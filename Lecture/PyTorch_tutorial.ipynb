{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Quickstart Tutorial\n",
    "\n",
    "---\n",
    "\n",
    "<i>This tutorial is to introduce the basics of using PyTorch.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Working with data](#working-with-data)\n",
    "2. [Creating Models](#creating-models)\n",
    "3. [Optimizing the Model Parameters](optimzing-the-model-parameters)\n",
    "4. [Saving Models](#saving-models)\n",
    "5. [Loading Models](#loading-models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Working with data\n",
    "- [Dataset](#dataset)\n",
    "- [DataLoader](#dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "#### What is `Dataset`?\n",
    "- Storage of the samples and their corresponding labels\n",
    "- `torchvision.datasets` module contains `Dataset` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "\n",
    "### FashionMNIST: Dataset with 60000, 28x18 grayscale images in 10 categories ###\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),  ## \"transform\" the data to \"tensor\" format\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for better understanding..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "### We can see that the number of training data is 60000 ###\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "### We can see what's in the training_data: tuple with tensor and label ###\n",
    "return_something = training_data[0]\n",
    "# print(return_something)\n",
    "print(type(return_something))  ## this 'tuple': (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "### ToTensor(): convert np.ndarray ---> torch.FlaotTensor ###\n",
    "    # It converts\n",
    "    # PIL Image or np.ndarray -----------> torch.FloatTensor\n",
    "    #   in the range [0, 255]           in the range [0.0, 1.0]\n",
    "    #       (H x W x C)                       (C x H x W)\n",
    "    # (Height x Width x Channel)      (Channel x Height x Width)\n",
    "\n",
    "    # if the PIL Image belongs to one of the models (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)\n",
    "    # or if the numpy.ndarray has dtype = np.uint8\n",
    "\n",
    "# Check a data (index: 0)\n",
    "img, label = training_data[0]\n",
    "print(img.shape)  # torch.Size([channel, height, width])\n",
    "print(label)  # this image is labeled to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example for `Dataset`\n",
    "- Every TorchVision `Dataset` includes two arguments to modify the samples & labels respectively:\n",
    "    - `transform`\n",
    "    - `target_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from torchvision.io import read_image\n",
    "\n",
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(annotations_file)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "#### What is `DataLoader`?\n",
    "- Wraps an iterable around the `Dataset`\n",
    "- Supports automatic batching, sampling, shuffling, and multiprocess data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Define a batch size of 64\n",
    "batch_size = 64  ## each element in the dataloader iterable will return a batch of 64 features & labels\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# How dataloader work\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "# Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) => meaning: dataloader now want to run 64 times and stack everything to new exit\n",
    "# (C, H, W) ---------> (B, C, H, W)\n",
    "#           (Batch_size, Channel, Height, Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For better understanding..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len DataLoader: 157\n",
      "Len DataLoader: 938\n"
     ]
    }
   ],
   "source": [
    "print(f\"Len DataLoader: {len(test_dataloader)}\")\n",
    "print(f\"Len DataLoader: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000 / 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Creating Models\n",
    "- [Devices](#devices)\n",
    "- [Define a Neural Network](#define-a-neural-network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devices\n",
    "\n",
    "#### Device Setup\n",
    "- To accelerate operations in the neural network, we move it to the GPU or MPS if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"  # meaning: working on GPU\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"  # meaning: MacOS\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")  # represents the device we're gonna run on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Neural Network\n",
    "- Create a class that inherits from `nn.Module` to define a neural network in PyTorch.\n",
    "    - Define the layers of the network in the `__init__` function\n",
    "    - Specify how data will pass through the network in the `forward` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's `nn`?\n",
    "    - `import torch.nn as nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "class NeuralNetwork(nn.Module):  # inherited from \".Module\"\n",
    "    def __init__(self):\n",
    "        super().__init__()  # when we call an instance, it will run the class Module => so we use super().__init__()\n",
    "        # REMEMBER: whenever you create a model, you have to inherit from Module, so we use super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)  # final output number is 10; because of the number of categories is 10\n",
    "        )  # sequential layer\n",
    "\n",
    "    def forward(self, x):  # model(x)\n",
    "        x = self.flatten(x)  # (B, 1 * 28 * 28) = (B, C * H * W)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)  # to operate model in right device; if input is cpu but the model runs in gpu, ERROR!\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For better understanding..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(64, 1, 28, 28, device=device)\n",
    "flattened_x = model.flatten(x)\n",
    "print(flattened_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "mlp = model.linear_relu_stack[0]\n",
    "print(mlp.weight.shape)\n",
    "print(mlp.bias.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
